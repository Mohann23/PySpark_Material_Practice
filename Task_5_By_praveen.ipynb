{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_5_By_praveen.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYg7eYX9SujrnnTM7Ar64J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohann23/PySpark_Material_Practice/blob/master/Task_5_By_praveen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DFVnTaCWgLZ",
        "outputId": "05a4e1be-a762-4072-fadc-c49db4a11ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "\n",
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "\n",
        "\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "findspark.find()\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Task_5').getOrCreate()"
      ],
      "metadata": {
        "id": "A3VlH_3AW9wp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record = spark.read.csv('/content/drive/MyDrive/PYSpark_Files/Day_4_task_4.csv',inferSchema=True,header=True)"
      ],
      "metadata": {
        "id": "dGxMxD4WXLlP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAvP3X7j5sEg",
        "outputId": "686bcda2-f607-4385-db93-df26172d60dc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------+----------+------+-----------+\n",
            "|userid|         emailid|      date|amount|   discount|\n",
            "+------+----------------+----------+------+-----------+\n",
            "|     1| test1@gmail.com|01-01-2019|   100|        1.0|\n",
            "|     2| test2@gmail.com|02-01-2019|   100|        1.0|\n",
            "|     3|  test3gmail.com|03-01-2019|   101|        2.0|\n",
            "|     4| test4@gmail.com|04-01-2019|   102|       10.0|\n",
            "|     5| test5@gmail.com|05-01-2019| 102.5|        2.0|\n",
            "|     6| test6@gmail.com|06-01-2019| 103.2|        1.0|\n",
            "|     7| test7@gmail.com|07-01-2019| 103.9|        3.0|\n",
            "|     8|  test8@gmailcom|08-01-2019| 104.6|        5.0|\n",
            "|     9| test9@gmail.com|09-01-2019| 105.3|4.571428571|\n",
            "|    10|test10@gmail.com|01-10-2019|   106|4.892857143|\n",
            "|    11|test11@gmail.com|  11-02-19| 106.7|5.214285714|\n",
            "|    12|   test12@gmail.|12-01-2019| 107.4|5.535714286|\n",
            "|    13|test13@gmail.com|2019-01-13| 108.1|5.857142857|\n",
            "|    14|test14@gmail.com|14-01-2019| 108.8|6.178571429|\n",
            "|    15|test15@gmail.com|15-01-2019| 109.5|        6.5|\n",
            "|    16|test16@gmail.com|16-01-2019| 110.2|6.821428571|\n",
            "|    17|test17@gmail.com|17-01-2019| 110.9|7.142857143|\n",
            "|    18|test18@gmail.com|18-01-2019| 111.6|7.464285714|\n",
            "|    19|test19@gmail.com|19-01-2019| 112.3|7.785714286|\n",
            "|    20|test20@gmail.com|20-01-2019|   113|8.107142857|\n",
            "+------+----------------+----------+------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "def func_date(str1):\n",
        "  for fmt in ('%Y-%m-%d', '%d.%m.%Y', '%d/%m/%Y','%d-%m-%Y','%dd-%mm-%yyyy','%d-%b-%Y','%d-%B-%Y','%y-%m-%d','%d %b %Y','%d %B %Y'):\n",
        "    try:\n",
        "      date_object =  datetime.strptime(str1, fmt)\n",
        "      converted_date = date_object.strftime('%Y-%m-%d')\n",
        "      return converted_date\n",
        "    except ValueError:\n",
        "      pass\n",
        "  raise ValueError('no valid date format found')"
      ],
      "metadata": {
        "id": "HTngHsHV4EOQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_udf = udf(lambda str1: func_date(str1))"
      ],
      "metadata": {
        "id": "CjNAY1sR5YbZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_change = record.select(col('date'),date_udf(col('date').alias(\"Updated_date\")))"
      ],
      "metadata": {
        "id": "opj_UjGi5dBr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_change.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vejXSyzm5mdI",
        "outputId": "5b386f99-c3bc-4dfb-bcbb-f2d8b575ad54"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------------------+\n",
            "|      date|<lambda>(date AS Updated_date)|\n",
            "+----------+------------------------------+\n",
            "|01-01-2019|                    2019-01-01|\n",
            "|02-01-2019|                    2019-01-02|\n",
            "|03-01-2019|                    2019-01-03|\n",
            "|04-01-2019|                    2019-01-04|\n",
            "|05-01-2019|                    2019-01-05|\n",
            "|06-01-2019|                    2019-01-06|\n",
            "|07-01-2019|                    2019-01-07|\n",
            "|08-01-2019|                    2019-01-08|\n",
            "|09-01-2019|                    2019-01-09|\n",
            "|01-10-2019|                    2019-10-01|\n",
            "|  11-02-19|                    2011-02-19|\n",
            "|12-01-2019|                    2019-01-12|\n",
            "|2019-01-13|                    2019-01-13|\n",
            "|14-01-2019|                    2019-01-14|\n",
            "|15-01-2019|                    2019-01-15|\n",
            "|16-01-2019|                    2019-01-16|\n",
            "|17-01-2019|                    2019-01-17|\n",
            "|18-01-2019|                    2019-01-18|\n",
            "|19-01-2019|                    2019-01-19|\n",
            "|20-01-2019|                    2019-01-20|\n",
            "+----------+------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "s1TtGMQX5pOO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}